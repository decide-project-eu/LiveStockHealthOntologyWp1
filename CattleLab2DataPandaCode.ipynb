{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d32abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas\n",
    "! pip install openpyxl\n",
    "\n",
    "import pandas as pd\n",
    "import rdflib\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from rdflib import Literal, Namespace, RDF, URIRef\n",
    "from rdflib.namespace import FOAF, XSD\n",
    "from rdflib import Graph, Namespace, RDF, RDFS, OWL\n",
    "from rdflib.plugins.sparql import prepareQuery\n",
    "from pyspark.sql.functions import when, col, lit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f5d238",
   "metadata": {},
   "source": [
    "### Step01: Define The file paths and load Data into Pandas dataframes and Clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17dfdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths\n",
    "files = ['Data/Lab2/221122_data_Lab2_DECIDE_nw (2).xlsx']\n",
    "\n",
    "# Load the data into Pandas dataframes\n",
    "dfs = []\n",
    "for file in files:\n",
    "    df = pd.read_excel(file, engine='openpyxl')\n",
    "    dfs.append(df)\n",
    "\n",
    "barometer_dt_raw = dfs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06619366",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rename columns and replace variable names\n",
    "barometer_dt = barometer_dt_raw.rename(columns={\n",
    "    'Dossier_ID': 'FileNumber',\n",
    "    'sample_id': 'SampleNumber',\n",
    "    'farm_ID': 'FarmID',\n",
    "    'project': 'Project',\n",
    "    'date': 'Date',\n",
    "    'Lab_reference': 'LabReference',\n",
    "    'Sample_type': 'SampleType',\n",
    "    'Diagnostic_test': 'DiagnosticTest'\n",
    "})\n",
    "\n",
    "# Define functions for hashing\n",
    "def sha256_hash(text):\n",
    "    return hashlib.sha256(text.encode('utf-8')).hexdigest()\n",
    "\n",
    "# Define mappings for Sample_type, Diagnostic_test, Breed, and Province\n",
    "sample_type_mapping = {\n",
    "    'Autopsy': 'Autopsy',\n",
    "    'BAL': 'BAL',\n",
    "    'SWABS': 'Swab',\n",
    "    'OTHER': 'Unknown'\n",
    "}\n",
    "\n",
    "diagnostic_test_mapping = {\n",
    "    'PCR': 'PCR',\n",
    "    'Kweek': 'Culture'\n",
    "}\n",
    "\n",
    "breed_mapping = {\n",
    "    'beef': 'Beef',\n",
    "    'dairy': 'Dairy',\n",
    "    'mixed': 'Mixed',\n",
    "    'veal': 'Veal',\n",
    "    'other': 'Unknown',\n",
    "    'rearing': 'Unknown',\n",
    "    'unknown': 'Unknown'\n",
    "}\n",
    "\n",
    "province_mapping = {\n",
    "    'DR': 'Drenthe',\n",
    "    'FL': 'Flevoland',\n",
    "    'FR': 'Friesland',\n",
    "    'GL': 'Gelderland',\n",
    "    'GR': 'Groningen',\n",
    "    'LB': 'Limburg',\n",
    "    'NB': 'North Brabant',\n",
    "    'NH': 'North Holland',\n",
    "    'OV': 'Overijssel',\n",
    "    'UT': 'Utrecht',\n",
    "    'ZH': 'South Holland',\n",
    "    'ZL': 'Zeeland'\n",
    "}\n",
    "# Perform the data manipulation using pandas\n",
    "barometer_dt = barometer_dt.assign(\n",
    "    Country='The Netherlands',\n",
    "    LabReference='2',\n",
    "    SampleType=barometer_dt['reason_of_sampling'].map(sample_type_mapping).fillna('Missing'),\n",
    "    DiagnosticTest=barometer_dt['test'].map(diagnostic_test_mapping).fillna('Missing'),\n",
    "    Breed=barometer_dt['breed'].map(breed_mapping).fillna('Unknown'),\n",
    "    Province=barometer_dt['provincie'].map(province_mapping).fillna('Missing')\n",
    ")\n",
    "\n",
    "barometer_dt = barometer_dt[['FileNumber', 'DiagnosticTest', 'SampleNumber', 'Country', 'LabReference', 'SampleType', 'Breed', 'PM', 'MH', 'HS', 'MB', 'BRSV', 'PI3', 'BCV', 'Date', 'Province', 'Project', 'FarmID']]\n",
    "\n",
    "# Drop duplicate rows\n",
    "barometer_dt = barometer_dt.drop_duplicates()\n",
    "\n",
    "# Apply sha256 hashing on FileNumber, SampleNumber, and FarmID columns\n",
    "barometer_dt['FileNumber'] = barometer_dt['FileNumber'].apply(sha256_hash)\n",
    "barometer_dt['SampleNumber'] = barometer_dt['SampleNumber'].astype(str).apply(sha256_hash)\n",
    "barometer_dt['FarmID'] = barometer_dt['FarmID'].astype(str).apply(sha256_hash)\n",
    "#print(barometer_dt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f917fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "barometer_dt_filtered = barometer_dt[(barometer_dt['Project'] == 'monitoring') | (barometer_dt['Project'] == 'no project')]\n",
    "# Floor date to the 1st of the month using .loc method\n",
    "barometer_dt_filtered['Floored_date'] = barometer_dt_filtered['Date'].dt.to_period('M').dt.to_timestamp()\n",
    "# Aggregate data based on farm_ID and month (WIDE)\n",
    "agg_functions = {'PM': 'max', 'MH': 'max', 'HS': 'max', 'MB': 'max', 'BRSV': 'max', 'PI3': 'max', 'BCV': 'max'}\n",
    "barometer_groupby = barometer_dt_filtered.groupby(['LabReference', 'Country', 'Breed', 'Floored_date', 'Province', 'FarmID', 'DiagnosticTest', 'SampleType']).agg(agg_functions)\n",
    "\n",
    "# Convert to LONG\n",
    "barometer_groupby.columns = [f'{col[0]}_{col[1]}' for col in barometer_groupby.columns]\n",
    "barometer_long = pd.melt(barometer_groupby.reset_index(), id_vars=['LabReference', 'Country', 'Breed', 'Floored_date', 'Province', 'FarmID', 'DiagnosticTest', 'SampleType'], var_name='Pathogen', value_name='Result')\n",
    "# Save file to CSV (long version)\n",
    "barometer_long.to_csv(\"Data/CleanedData/barometer_GD.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da18d0cc",
   "metadata": {},
   "source": [
    "### Step 02: Create RDF graph and namespaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a15103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = rdflib.Graph()\n",
    "onto = Namespace(\"http://www.purl.org/decide/LivestockHealthOnto\")\n",
    "g.bind('onto', onto)\n",
    "xsd = Namespace('http://www.w3.org/2001/XMLSchema#')\n",
    "g.bind('xsd', xsd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e6c122",
   "metadata": {},
   "source": [
    "###  Step 03: Iterate over the Panda DataFrame and map to ontology properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f821b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the rows and create RDF triples\n",
    "for index, row in barometer_long.iterrows():\n",
    "    CattleSample = onto[f'CattleSample{row[\"LabReference\"]}_{index}']\n",
    "    g.add((CattleSample, RDF.type, onto.CattleSample))\n",
    "\n",
    "    # Handle nan values in literals\n",
    "    diagnostic_test = row['DiagnosticTest'] if not pd.isna(row['DiagnosticTest']) else \"\"\n",
    "    country = row['Country'] if not pd.isna(row['Country']) else \"\"\n",
    "    lab_reference = row['LabReference'] if not pd.isna(row['LabReference']) else \"\"\n",
    "    sample_type = row['SampleType'] if not pd.isna(row['SampleType']) else \"\"\n",
    "    breed = row['Breed'] if not pd.isna(row['Breed']) else \"\"\n",
    "    Pathogen = row['Pathogen'] if not pd.isna(row['Pathogen']) else \"\"\n",
    "    result = row['Result'] if not pd.isna(row['Result']) else \"Missing\"\n",
    "    date = row['Floored_date'] if not pd.isna(row['Floored_date']) else \"\"\n",
    "    province = row['Province'] if not pd.isna(row['Province']) else \"\"\n",
    "    farm_id = row['FarmID'] if not pd.isna(row['FarmID']) else \"\"\n",
    "\n",
    "    g.add((CattleSample, onto.hasDiagnosticTest, Literal(diagnostic_test, datatype=XSD.string)))\n",
    "    g.add((CattleSample, onto.hasCountry, Literal(country, datatype=XSD.string)))\n",
    "    g.add((CattleSample, onto.hasLabReference, Literal(lab_reference, datatype=XSD.string)))\n",
    "    g.add((CattleSample, onto.hasSampleType, Literal(sample_type, datatype=XSD.string)))\n",
    "    g.add((CattleSample, onto.hasBreed, Literal(breed, datatype=XSD.string)))\n",
    "    g.add((CattleSample, onto.hasResult, Literal(result, datatype=XSD.string)))\n",
    "    g.add((CattleSample, onto.hasDate, Literal(date, datatype=XSD.string)))\n",
    "    g.add((CattleSample, onto.hasProvince, Literal(province, datatype=XSD.string)))\n",
    "    g.add((CattleSample, onto.hasFarmIdentification, Literal(farm_id, datatype=XSD.string)))\n",
    "    g.add((CattleSample, onto.hasPathogen, Literal(Pathogen, datatype=XSD.string)))\n",
    "\n",
    "g.serialize(destination='output/RDFoutputCattleSampleLab2.ttl', format='turtle')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f13e325",
   "metadata": {},
   "source": [
    "### Step 4: Load the RDF data and ontology into a Panda DataFrame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0cba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the original path\n",
    "path_to_RDF = \"output/RDFoutputCattleSampleLab2.ttl\"\n",
    "\n",
    "# Try to parse the file and catch any errors\n",
    "try:\n",
    "    # Create a new graph\n",
    "    g = Graph()\n",
    "\n",
    "    # Parse the RDF file in Turtle format\n",
    "    g.parse(path_to_RDF, format='ttl')\n",
    "\n",
    "    # Parse the ontology file in OWL format and add it to the graph\n",
    "    path_to_ontology = \"Ontology/LivestockHealthOnto1.0.owl\"\n",
    "    g.parse(path_to_ontology, format=\"xml\")\n",
    "    \n",
    "except Exception as e:\n",
    "    # Print the error message\n",
    "    print(f\"An error occurred while parsing the RDF file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d7a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use RDFS or OWL reasoning to infer additional knowledge\n",
    "g.bind('rdfs', RDFS)\n",
    "g.bind('owl', OWL)\n",
    "g.bind('onto', Namespace(\"http://www.purl.org/decide/LivestockHealthOnto\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feba332",
   "metadata": {},
   "source": [
    "### Step 05: Query the data from updated ontology "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SPARQL query and Query the data from the updated ontology (Simple Query)\n",
    "query = \"\"\"\n",
    "PREFIX onto: <http://www.purl.org/decide/LivestockHealthOnto>\n",
    "SELECT ?FarmIdentification ?SampleType ?DiagnosticTest ?Date ?Breed ?LabReference ?Result ?Pathogen ?Province ?Country\n",
    "WHERE {\n",
    "  ?CattleSample onto:hasFarmIdentification ?FarmIdentification .\n",
    "  ?CattleSample onto:hasSampleType ?SampleType .\n",
    "  ?CattleSample onto:hasDiagnosticTest ?DiagnosticTest .\n",
    "  ?CattleSample onto:hasDate ?Date .\n",
    "  ?CattleSample onto:hasBreed ?Breed .\n",
    "  ?CattleSample onto:hasLabReference ?LabReference .\n",
    "  ?CattleSample onto:hasResult ?Result .\n",
    "  ?CattleSample onto:hasPathogen ?Pathogen .\n",
    "  ?CattleSample onto:hasProvince ?Province .\n",
    "  ?CattleSample onto:hasCountry ?Country .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# execute the query and retrieve the results\n",
    "results = g.query(query)\n",
    "\n",
    "# convert the results to a Pandas dataframe\n",
    "data = []\n",
    "for row in results:\n",
    "    data.append(list(row))\n",
    "df = pd.DataFrame(data, columns=[\"FarmIdentification\",\"SampleType\",\"DiagnosticTest\", \"Date\", \"Breed\", \"LabReference\", \"Result\", \"Pathogen\", \"Province\", \"Country\"])\n",
    "\n",
    "# display the dataframe\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This SPARQL query shows the data over filter if SampleType is Autopsy, diagnostic Test is PCR and Breed is Dairy \n",
    "query = \"\"\"\n",
    "PREFIX onto: <http://www.purl.org/decide/LivestockHealthOnto>\n",
    "SELECT ?FarmIdentification ?SampleType ?DiagnosticTest ?Date ?Breed ?LabReference ?Result ?Pathogen ?Province ?Country\n",
    "WHERE {\n",
    "  ?CattleSample onto:hasFarmIdentification ?FarmIdentification .\n",
    "  ?CattleSample onto:hasSampleType ?SampleType .\n",
    "  FILTER (?SampleType = \"Autopsy\")\n",
    "  ?CattleSample onto:hasDiagnosticTest ?DiagnosticTest .\n",
    "  FILTER (?DiagnosticTest = \"PCR\")\n",
    "  ?CattleSample onto:hasDate ?Date .\n",
    "  ?CattleSample onto:hasBreed ?Breed .\n",
    "  FILTER (?Breed = \"Dairy\")\n",
    "  ?CattleSample onto:hasLabReference ?LabReference .\n",
    "  ?CattleSample onto:hasResult ?Result .\n",
    "  ?CattleSample onto:hasPathogen ?Pathogen .\n",
    "  ?CattleSample onto:hasProvince ?Province .\n",
    "  ?CattleSample onto:hasCountry ?Country .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# execute the query and retrieve the results\n",
    "results = g.query(query)\n",
    "\n",
    "# convert the results to a Pandas dataframe\n",
    "data = []\n",
    "for row in results:\n",
    "    data.append(list(row))\n",
    "df = pd.DataFrame(data, columns=[\"FarmIdentification\",\"SampleType\",\"DiagnosticTest\", \"Date\", \"Breed\", \"LabReference\", \"Result\", \"Pathogen\", \"Province\", \"Country\"])\n",
    "\n",
    "# display the dataframe\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad196ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
