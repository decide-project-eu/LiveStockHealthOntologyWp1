{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56906ea1",
   "metadata": {},
   "source": [
    "##Install and Import the necessary classes from the RDFlib library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d618ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdflib in c:\\users\\saban\\anaconda3\\lib\\site-packages (6.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\saban\\anaconda3\\lib\\site-packages (from rdflib) (63.4.1)\n",
      "Requirement already satisfied: isodate in c:\\users\\saban\\anaconda3\\lib\\site-packages (from rdflib) (0.6.1)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\saban\\anaconda3\\lib\\site-packages (from rdflib) (3.0.9)\n",
      "Requirement already satisfied: six in c:\\users\\saban\\anaconda3\\lib\\site-packages (from isodate->rdflib) (1.16.0)\n",
      "Requirement already satisfied: owlrl in c:\\users\\saban\\anaconda3\\lib\\site-packages (6.0.2)\n",
      "Requirement already satisfied: rdflib>=6.0.2 in c:\\users\\saban\\anaconda3\\lib\\site-packages (from owlrl) (6.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\saban\\anaconda3\\lib\\site-packages (from rdflib>=6.0.2->owlrl) (63.4.1)\n",
      "Requirement already satisfied: isodate in c:\\users\\saban\\anaconda3\\lib\\site-packages (from rdflib>=6.0.2->owlrl) (0.6.1)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\saban\\anaconda3\\lib\\site-packages (from rdflib>=6.0.2->owlrl) (3.0.9)\n",
      "Requirement already satisfied: six in c:\\users\\saban\\anaconda3\\lib\\site-packages (from isodate->rdflib>=6.0.2->owlrl) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install rdflib\n",
    "! pip install owlrl\n",
    "from rdflib import Graph, Literal, Namespace, RDF, URIRef\n",
    "from rdflib.namespace import FOAF, XSD\n",
    "from rdflib import Graph, Namespace, RDF, RDFS, OWL\n",
    "from rdflib.plugins.sparql import prepareQuery\n",
    "import pandas as pd\n",
    "import rdflib\n",
    "import pyspark \n",
    "import os\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col,lit\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, isnan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59666440",
   "metadata": {},
   "source": [
    "### Step1: Create a SparkSession and read the Excel file into a PySpark DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc17fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('DataCleaning').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b02353ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths\n",
    "files = ['DGZ/DECIDE_MTA_UGENT_14nov2022.xlsx', \n",
    "         'DGZ/DECIDE_MTA_UGENT_BAC_AERO_14nov2022.xlsx', \n",
    "         'DGZ/DECIDE_MTA_UGENTBAC_MYCO_14nov2022.xlsx']\n",
    "\n",
    "# Load the data into Spark dataframes\n",
    "dfs = []\n",
    "for file in files:\n",
    "    df = spark.read.format('com.crealytics.spark.excel') \\\n",
    "                .option('header', 'true') \\\n",
    "                .option('inferSchema', 'true') \\\n",
    "                .load(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "barometer_dt_raw = dfs[0]\n",
    "barometer_aero_cult_raw = dfs[1]\n",
    "barometer_myco_cult_raw = dfs[2]\n",
    "#barometer_aero_cult_raw .show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab91821",
   "metadata": {},
   "source": [
    "#### Step 2: Create an RDF graph and namespaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c831c5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = rdflib.Graph()\n",
    "onto = Namespace(\"http://example.com/animal_health#\")\n",
    "g.bind('onto', onto)\n",
    "xsd = Namespace('http://www.w3.org/2001/XMLSchema#')\n",
    "g.bind('xsd', xsd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18fde6d",
   "metadata": {},
   "source": [
    "### Step 03: Iterate over the PySpark DataFrame and map to ontology properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d1370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation AEROBIC CULTURE results\n",
    "barometer_aero_cult = barometer_aero_cult_raw \\\n",
    "    .withColumnRenamed(\"Dossiernummer\", \"Filenumber\") \\\n",
    "    .withColumnRenamed(\"KIEMSTAAL IDENTIFICATIE\", \"Pathogen_identification\") \\\n",
    "    .withColumnRenamed(\"KIEMSTAAL RESULTAAT\", \"Pathogen_result\") \\\n",
    "    .withColumnRenamed(\"Staalnummer\", \"Samplenumber\") \\\n",
    "    .withColumn(\"Parameter_code\", lit(\"BAC_AERO\")) \\\n",
    "    .withColumn(\"Result\", lit(\"OK\")) \\\n",
    "    .select(\"Filenumber\", \"Pathogen_identification\", \"Pathogen_result\", \"Parameter_code\", \"Samplenumber\", \"Result\") \\\n",
    "    .filter(col(\"Pathogen_identification\").isin(\"Pasteurella multocida\", \"Mannheimia haemolytica\", \"Histophilus somni\", \"Mycoplasma bovis\")) \\\n",
    "    .distinct()\n",
    "\n",
    "\n",
    "df_samples = spark.createDataFrame([\n",
    "  (\"OK\", \"BAC_AERO\", \"Culture\", \"Pasteurella multocida\"),\n",
    "  (\"OK\", \"BAC_AERO\", \"Culture\", \"Mannheimia haemolytica\"),\n",
    "  (\"OK\", \"BAC_AERO\", \"Culture\", \"Histophilus somni\"),\n",
    "  (\"OK\", \"BAC_MYCOPLASMA\", \"Culture\", \"Mycoplasma bovis\")\n",
    "], [\"Result\", \"Parameter_code\", \"Diagnostic_test\", \"Pathogen_identification\"])\n",
    " \n",
    "#barometer_aero_cult.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9e6534",
   "metadata": {},
   "source": [
    "### Data manipulation MYCOPLASMA CULTURE results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb9dd463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation MYCOPLASMA CULTURE results\n",
    "barometer_myco_cult = barometer_myco_cult_raw \\\n",
    "    .withColumnRenamed(\"Dossiernummer\", \"Filenumber\") \\\n",
    "    .withColumnRenamed(\"KIEMSTAAL IDENTIFICATIE\", \"Pathogen_identification\") \\\n",
    "    .withColumnRenamed(\"KIEMSTAAL RESULTAAT\", \"Mycoplasma_result\") \\\n",
    "    .withColumnRenamed(\"Staalnummer\", \"Samplenumber\") \\\n",
    "    .withColumn(\"Parameter_code\", lit(\"BAC_MYCOPLASMA\")) \\\n",
    "    .withColumn(\"Result\", lit(\"OK\")) \\\n",
    "    .select(\"Filenumber\", \"Pathogen_identification\", \"Mycoplasma_result\", \"Parameter_code\", \"Samplenumber\", \"Result\") \\\n",
    "    .filter(col(\"Pathogen_identification\").isin(\"Mycoplasma bovis\")) \\\n",
    "    .distinct()\n",
    "\n",
    "#barometer_myco_cult.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63ddade",
   "metadata": {},
   "source": [
    "### Data manipulation PCR results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "371358e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation PCR results\n",
    "barometer_dtt = barometer_dt_raw \\\n",
    "    .withColumnRenamed(\"Dossiernummer\", \"Filenumber\")\\\n",
    "    .withColumnRenamed(\"Staalnummer\", \"Samplenumber\")\\\n",
    "    .withColumnRenamed(\"Staaltype\", \"Sample_type\") \\\n",
    "    .withColumnRenamed(\"PARAMETER_CODE\", \"Parameter_code\")\\\n",
    "    .withColumnRenamed(\"Onderzoek\", \"Pathogen\")\\\n",
    "    .withColumnRenamed(\"Resultaat\", \"Result\")\\\n",
    "    .withColumnRenamed(\"Creatiedatum\", \"Date\")\\\n",
    "    .withColumnRenamed(\"Postcode\", \"Postal_code\")\\\n",
    "    .withColumnRenamed(\"ANON_ID\", \"Farm_ID\")\\\n",
    "    .withColumn(\"Country\", when(col(\"Parameter_code\").isin(\"BAC_AERO\", \"BAC_MYCOPLASMA\"), \"Belgium\")) \\\n",
    "    .withColumn(\"Diagnostic_test\", when(col(\"Parameter_code\").isin(\"BAC_AERO\", \"BAC_MYCOPLASMA\"), \"Culture\").otherwise(\"PCR\")) \\\n",
    "    .withColumn(\"Lab_reference\", lit(\"1\"))\\\n",
    "    .withColumn(\"Sample_type\", when(col(\"Sample_type\") == \"RU Broncho-alveolar lavage (BAL)\", \"BAL\")\n",
    "        .when(col(\"Sample_type\") == \"RU Anderen\", \"Unknown\")\n",
    "        .when(col(\"Sample_type\").isin(\"RU Swabs\", \"RU Swab\", \"RU Neusswab\", \"RU Neusswabs\"), \"Swab\")\n",
    "        .when(col(\"Sample_type\").isin(\"RU Kadaver\", \"RU Organen\"), \"Autopsy\")\n",
    "        .otherwise(\"Missing\")) \\\n",
    "    .withColumn(\"Breed\", when(col(\"Bedrijfstype\") == \"VCALF\", \"Veal\")\n",
    "        .when(col(\"MEAT\").isNull(), \"Unknown\")\n",
    "        .when((col(\"MEAT\") / col(\"TOTAL\")) > 0.9, \"Beef\")\n",
    "        .when((col(\"MILK\") / col(\"TOTAL\")) > 0.9, \"Dairy\")\n",
    "        .otherwise(\"Mixed\")) \\\n",
    "    .withColumn(\"Pathogen\",\n",
    "        when(col(\"Pathogen\").isin(\n",
    "            \"AD Pasteurella multocida Ag (PCR)\",\n",
    "            \"AD Pasteurella multocida Ag pool (PCR)\",\n",
    "            \"AD P. multocida Ag (PCR)\"\n",
    "            \"AD P. multocida Ag pool (PCR)\"),\"Pasteurella multocida\")\n",
    "               .when(col(\"Pathogen\").isin(\n",
    "                        \"AD Mannheimia haemolytica Ag (PCR)\",\n",
    "                        \"AD Mannheimia haemolytica Ag pool (PCR)\"), \"Mannheimia haemolytica\")\n",
    "               .when(col(\"Pathogen\").isin(\n",
    "                        \"RU PI3 Ag (PCR)\",\n",
    "                        \"RU PI3 Ag pool (PCR)\"), \"PI3\")\n",
    "               .when(col(\"Pathogen\").isin(\n",
    "                        \"RU BRSV Ag (PCR)\",\n",
    "                        \"RU BRSV Ag pool (PCR)\"), \"BRSV\")\n",
    "               .when(col(\"Pathogen\").isin(\n",
    "                        \"AD Histophilus somnus (PCR)\",\n",
    "                        \"AD Histophilus somnus Ag (PCR)\",\n",
    "                        \"AD Histophilus somnus Ag pool (PCR)\",\n",
    "                        \"AD Histophilus somni Ag (PCR)\",\n",
    "                    \"AD Histophilus somni Ag pool (PCR)\"), \"Histophilus somni\")\n",
    "           .when(col(\"Pathogen\").isin(\n",
    "                    \"RU Mycoplasma bovis (PCR)\",\n",
    "                    \"RU Mycoplasma bovis Ag pool (PCR)\",\n",
    "                    \"RU Mycoplasma bovis Ag (PCR)\"), \"Mycoplasma bovis\")\n",
    "           .when(col(\"Pathogen\").isin(\n",
    "                    \"AD Corona Ag (PCR)\", \"AD Corona Ag pool (PCR)\"), \"BCV\")) \\\n",
    ".withColumn(\"Province\", \n",
    "                   when(col(\"Postal_code\").between(1000, 1299), \"Brussels\") \\\n",
    "                   .when(col(\"Postal_code\").between(1300, 1499), \"Walloon Brabant\") \\\n",
    "                   .when(col(\"Postal_code\").between(1500, 1999), \"Flemish Brabant\") \\\n",
    "                   .when(col(\"Postal_code\").between(3000, 3499), \"Antwerp\") \\\n",
    "                   .when(col(\"Postal_code\").between(2000, 2999), \"Limburg\") \\\n",
    "                   .when(col(\"Postal_code\").between(5000, 5999), \"Namur\") \\\n",
    "                   .when(col(\"Postal_code\").between(6000, 6599), \"Hainaut\") \\\n",
    "                   .when(col(\"Postal_code\").between(7000, 7999), \"Hainaut\") \\\n",
    "                   .when(col(\"Postal_code\").between(6600, 6999), \"Luxembourg\") \\\n",
    "                   .when(col(\"Postal_code\").between( 8000, 8999), \"West Flanders\") \\\n",
    "                   .otherwise(\"East Flanders\"))\n",
    "            \n",
    "barometer_dtt= barometer_dtt.select(\"Filenumber\", \"Diagnostic_test\", \"Samplenumber\", \"Country\", \"Lab_reference\", \"Sample_type\", \"Breed\", \"Parameter_code\", \"Result\", \"Pathogen\", \"Date\", \"Postal_code\", \"Province\", \"Farm_ID\") \\\n",
    "    .distinct() \n",
    "\n",
    "#barometer_dtt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772271c3",
   "metadata": {},
   "source": [
    "### All three joins and clean file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbcf70b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "barometer = barometer_dtt.join(df_samples, ['Diagnostic_test', 'Result', 'Parameter_code'], 'left') \\\n",
    "                       .join(barometer_aero_cult, ['Filenumber', 'Samplenumber', 'Result', 'Parameter_code', 'Pathogen_identification'], 'left') \\\n",
    "                       .join(barometer_myco_cult, ['Filenumber', 'Samplenumber', 'Result', 'Parameter_code', 'Pathogen_identification'], 'left') \\\n",
    "                       .withColumn('Pathogen', when(col('Pathogen') == 'Pasteurella multocida', 'PM') \\\n",
    "                                             .when(col('Pathogen') == 'Histophilus somni', 'HS') \\\n",
    "                                             .when(col('Pathogen') == 'Mannheimia haemolytica', 'MH') \\\n",
    "                                             .when(col('Pathogen') == 'Mycoplasma bovis', 'MB') \\\n",
    "                                             .otherwise(col('Pathogen'))) \\\n",
    "                       .withColumn('Pathogen', when(col('Pathogen_identification') == 'Pasteurella multocida', 'PM') \\\n",
    "                                             .when(col('Pathogen_identification') == 'Histophilus somni', 'HS') \\\n",
    "                                             .when(col('Pathogen_identification') == 'Mannheimia haemolytica', 'MH') \\\n",
    "                                             .when(col('Pathogen_identification') == 'Mycoplasma bovis', 'MB') \\\n",
    "                                             .otherwise(col('Pathogen'))) \\\n",
    "                       .withColumn('Result', when(col('Result').isin([\"Twijfelachtig (PCR)\", \"POSITIEF\", \"GEDETECTEERD\", \"GEDETECTEERD (sterk)\", \"GEDETECTEERD (zwak)\", \"GEDETECTEERD (matig)\", \"GEDETECTEERD (zeer sterk)\", \"GEDETECTEERD (zeer zwak)\"]), 1) \\\n",
    "                                             .when(col('Result').isin([\"negatief\", \"Niet gedetecteerd\"]), 0) \\\n",
    "                                             .when(col('Result').isin([\"NI\", \"niet interpreteerbaar\", \"Inhibitie\"]), None) \\\n",
    "                                             .when((col('Parameter_code') == 'BAC_AERO') & (col('Pathogen_result').isNull()), 0) \\\n",
    "                                             .when((col('Parameter_code') == 'BAC_AERO') & (col('Pathogen_result').isNotNull()), 1) \\\n",
    "                                             .when((col('Parameter_code') == 'BAC_MYCOPLASMA') & (col('Mycoplasma_result').isNull()), None) \\\n",
    "                                             .when((col('Parameter_code') == 'BAC_MYCOPLASMA') & (col('Mycoplasma_result') == 'neg'), 0) \\\n",
    "                                             .when((col('Parameter_code') == 'BAC_MYCOPLASMA') & (col('Mycoplasma_result').rlike('POS')), 1) \\\n",
    "                                             .otherwise(None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5a5dd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+------+--------------------+-----------------------+---------------+-------+-------------+-----------+-----+--------+-------------------+-----------+---------------+-------------+---------------+-----------------+\n",
      "|  Filenumber|    Samplenumber|Result|      Parameter_code|Pathogen_identification|Diagnostic_test|Country|Lab_reference|Sample_type|Breed|Pathogen|               Date|Postal_code|       Province|      Farm_ID|Pathogen_result|Mycoplasma_result|\n",
      "+------------+----------------+------+--------------------+-----------------------+---------------+-------+-------------+-----------+-----+--------+-------------------+-----------+---------------+-------------+---------------+-----------------+\n",
      "|TO-17-116224|TO-17-116224-001|     0|      BO_VIR_RSB_PCR|                   null|            PCR|   null|            1|        BAL|Mixed|    BRSV|2017-05-05 14:40:55|       9860|  East Flanders| BOVBE40_1019|           null|             null|\n",
      "|TO-16-291154|TO-16-291154-002|  null|AS_BAC_PAST_MULT_PCR|                   null|            PCR|   null|            1|    Autopsy|Mixed|      PM|2016-12-15 11:10:58|       9200|  East Flanders|  BOVBE40_919|           null|             null|\n",
      "|TO-17-148345|TO-17-148345-001|     1|AS_BAC_PAST_MULT_PCR|                   null|            PCR|   null|            1|        BAL| Beef|      PM|2017-06-16 09:44:39|       9420|  East Flanders|  BOVBE40_990|           null|             null|\n",
      "|TO-17-015608|TO-17-015608-001|     1|AS_BAC_PAST_MULT_PCR|                   null|            PCR|   null|            1|        BAL|Dairy|      PM|2017-01-20 13:56:04|       3870|  East Flanders| BOVBE70_1206|           null|             null|\n",
      "|TO-16-294355|TO-16-294355-001|     0|      BO_VIR_PI3_PCR|                   null|            PCR|   null|            1|        BAL|Dairy|     PI3|2016-12-20 11:04:15|       2310|        Limburg|  BOVBE10_209|           null|             null|\n",
      "|TO-17-040662|TO-17-040662-001|     0|      BO_VIR_PI3_PCR|                   null|            PCR|   null|            1|        BAL|Dairy|     PI3|2017-02-21 10:33:55|       8600|  West Flanders|  BOVBE31_751|           null|             null|\n",
      "|TO-17-130761|TO-17-130761-001|     0|      BO_VIR_PI3_PCR|                   null|            PCR|   null|            1|        BAL|Dairy|     PI3|2017-05-24 11:31:00|       2322|        Limburg|  BOVBE10_241|           null|             null|\n",
      "|TO-17-060499|TO-17-060499-001|     0|      BO_VIR_PI3_PCR|                   null|            PCR|   null|            1|        BAL|Mixed|     PI3|2017-03-08 11:38:31|       9690|  East Flanders| BOVBE40_1044|           null|             null|\n",
      "|TO-17-082993|TO-17-082993-001|     0|      BO_VIR_PI3_PCR|                   null|            PCR|   null|            1|        BAL|Dairy|     PI3|2017-03-30 13:55:17|       8432|  West Flanders|  BOVBE30_548|           null|             null|\n",
      "|TO-17-130578|TO-17-130578-002|     0|      BO_VIR_PI3_PCR|                   null|            PCR|   null|            1|    Autopsy| Beef|     PI3|2017-05-24 08:54:16|       8810|  West Flanders|  BOVBE30_422|           null|             null|\n",
      "|TO-17-163979|TO-17-163979-003|     0|      BO_VIR_PI3_PCR|                   null|            PCR|   null|            1|       Swab| Veal|     PI3|2017-07-07 14:26:30|       2460|        Limburg|VCALFBE10_144|           null|             null|\n",
      "|TO-17-017006|TO-17-017006-001|     0|      BO_VIR_PI3_PCR|                   null|            PCR|   null|            1|        BAL|Dairy|     PI3|2017-01-24 07:46:09|       2300|        Limburg|  BOVBE10_215|           null|             null|\n",
      "|TO-17-162738|TO-17-162738-004|     1| AS_BAC_PMULT_PCR_PO|                   null|            PCR|   null|            1|       Swab| Beef|      PM|2017-07-06 10:26:05|       8972|  West Flanders|  BOVBE30_723|           null|             null|\n",
      "|TO-17-125116|TO-17-125116-003|     1| AS_BAC_MHAEM_PCR_PO|                   null|            PCR|   null|            1|        BAL| Beef|      MH|2017-05-17 15:36:07|       3870|  East Flanders| BOVBE70_1110|           null|             null|\n",
      "|TO-17-162891|TO-17-162891-004|     1| AS_BAC_MHAEM_PCR_PO|                   null|            PCR|   null|            1|        BAL|Mixed|      MH|2017-07-06 12:57:11|       9800|  East Flanders|  BOVBE40_799|           null|             null|\n",
      "|TO-17-075911|TO-17-075911-001|     1|      BO_VIR_RSB_PCR|                   null|            PCR|   null|            1|    Autopsy| Beef|    BRSV|2017-03-23 13:57:54|       8700|  West Flanders|  BOVBE30_649|           null|             null|\n",
      "|TO-17-111152|TO-17-111152-001|     0| AS_BAC_MHAEM_PCR_PO|                   null|            PCR|   null|            1|        BAL|Mixed|      MH|2017-05-02 07:29:57|       2550|        Limburg|   BOVBE10_70|           null|             null|\n",
      "|TO-17-142878|TO-17-142878-005|     0| AS_BAC_MHAEM_PCR_PO|                   null|            PCR|   null|            1|        BAL|Dairy|      MH|2017-06-09 10:40:43|       8630|  West Flanders|  BOVBE30_569|           null|             null|\n",
      "|TO-16-291251|TO-16-291251-001|  null| AS_BAC_MAN_HAEM_PCR|                   null|            PCR|   null|            1|        BAL|Dairy|      MH|2016-12-15 14:28:24|       3900|  East Flanders| BOVBE70_1115|           null|             null|\n",
      "|TO-17-077223|TO-17-077223-001|  null| AS_BAC_MAN_HAEM_PCR|                   null|            PCR|   null|            1|        BAL|Dairy|      MH|2017-03-24 13:53:45|       9140|  East Flanders| BOVBE40_1056|           null|             null|\n",
      "|TO-16-299651|TO-16-299651-003|     0|   BO_BAC_MBOVIS_PCR|                   null|            PCR|   null|            1|    Autopsy| Beef|      MB|2016-12-27 11:19:17|       9190|  East Flanders|  BOVBE40_954|           null|             null|\n",
      "|TO-17-006360|TO-17-006360-001|     0|   BO_BAC_MBOVIS_PCR|                   null|            PCR|   null|            1|    Autopsy|Mixed|      MB|2017-01-10 11:10:44|       8600|  West Flanders|  BOVBE30_459|           null|             null|\n",
      "|TO-17-009425|TO-17-009425-001|     0|   BO_BAC_MBOVIS_PCR|                   null|            PCR|   null|            1|        BAL|Dairy|      MB|2017-01-12 14:01:52|       3530|  East Flanders| BOVBE70_1158|           null|             null|\n",
      "|TO-17-135849|TO-17-135849-001|     0|   BO_BAC_MBOVIS_PCR|                   null|            PCR|   null|            1|    Autopsy|Mixed|      MB|2017-05-31 16:26:09|       9920|  East Flanders| BOVBE40_1051|           null|             null|\n",
      "|TO-17-131024|TO-17-131024-010|     0|AS_VIR_CORONA_PCR_PO|                   null|            PCR|   null|            1|        BAL|Dairy|     BCV|2017-05-24 17:21:06|       8647|  West Flanders|  BOVBE30_714|           null|             null|\n",
      "|TO-16-285029|TO-16-285029-001|     1|      AS_BAC_HSO_PCR|                   null|            PCR|   null|            1|        BAL|Dairy|      HS|2016-12-08 10:54:21|       8647|  West Flanders|  BOVBE30_473|           null|             null|\n",
      "|TO-16-303495|TO-16-303495-001|     1|      AS_BAC_HSO_PCR|                   null|            PCR|   null|            1|    Autopsy| Beef|      HS|2016-12-30 15:01:17|       8902|  West Flanders|  BOVBE30_664|           null|             null|\n",
      "|TO-16-283790|TO-16-283790-001|     1|      AS_BAC_HSO_PCR|                   null|            PCR|   null|            1|        BAL|Mixed|      HS|2016-12-07 09:21:12|       1755|Flemish Brabant|  BOVBE20_309|           null|             null|\n",
      "|TO-17-144845|TO-17-144845-001|     0| BO_VIR_RSB_PCR_POOL|                   null|            PCR|   null|            1|        BAL|Mixed|    BRSV|2017-06-13 10:34:18|       9940|  East Flanders|  BOVBE40_812|           null|             null|\n",
      "|TO-17-065475|TO-17-065475-003|     0|   AS_VIR_CORONA_PCR|                   null|            PCR|   null|            1|    Autopsy| Beef|     BCV|2017-03-14 11:06:43|       8460|  West Flanders|  BOVBE30_493|           null|             null|\n",
      "|TO-17-003387|TO-17-003387-025|     0|   AS_VIR_CORONA_PCR|                   null|            PCR|   null|            1|        BAL|Dairy|     BCV|2017-01-05 13:04:00|       3920|  East Flanders| BOVBE70_1131|           null|             null|\n",
      "|TO-16-300871|TO-16-300871-002|     0|   AS_VIR_CORONA_PCR|                   null|            PCR|   null|            1|    Autopsy|Mixed|     BCV|2016-12-28 11:13:03|       3540|  East Flanders| BOVBE70_1172|           null|             null|\n",
      "|TO-17-123370|TO-17-123370-002|     0|AS_BAC_PAST_MULT_PCR|                   null|            PCR|   null|            1|       Swab|Mixed|      PM|2017-05-16 11:14:24|       9920|  East Flanders|  BOVBE40_847|           null|             null|\n",
      "|TO-17-060307|TO-17-060307-001|     1| AS_BAC_MAN_HAEM_PCR|                   null|            PCR|   null|            1|        BAL|Dairy|      MH|2017-03-08 08:37:25|       2990|        Limburg|   BOVBE10_53|           null|             null|\n",
      "|TO-17-011328|TO-17-011328-001|     0|      AS_BAC_HSO_PCR|                   null|            PCR|   null|            1|        BAL|Dairy|      HS|2017-01-16 16:05:34|       1670|Flemish Brabant|  BOVBE20_318|           null|             null|\n",
      "|TO-17-026698|TO-17-026698-001|     0|      AS_BAC_HSO_PCR|                   null|            PCR|   null|            1|        BAL|Dairy|      HS|2017-02-03 14:45:30|       2960|        Limburg|   BOVBE10_11|           null|             null|\n",
      "|TO-17-042339|TO-17-042339-005|     0|      AS_BAC_HSO_PCR|                   null|            PCR|   null|            1|       Swab| Beef|      HS|2017-02-22 10:36:34|       2500|        Limburg|   BOVBE10_89|           null|             null|\n",
      "|TO-17-081392|TO-17-081392-001|     0|      AS_BAC_HSO_PCR|                   null|            PCR|   null|            1|        BAL|Dairy|      HS|2017-03-29 11:41:08|       2322|        Limburg|  BOVBE10_241|           null|             null|\n",
      "|TO-16-291251|TO-16-291251-001|     0|      AS_BAC_HSO_PCR|                   null|            PCR|   null|            1|        BAL|Dairy|      HS|2016-12-15 14:28:24|       3900|  East Flanders| BOVBE70_1115|           null|             null|\n",
      "|TO-17-162738|TO-17-162738-001|     0| BO_VIR_PI3_PCR_POOL|                   null|            PCR|   null|            1|       Swab| Beef|     PI3|2017-07-06 10:26:05|       8972|  West Flanders|  BOVBE30_723|           null|             null|\n",
      "|TO-17-162891|TO-17-162891-001|     0| BO_VIR_PI3_PCR_POOL|                   null|            PCR|   null|            1|        BAL|Mixed|     PI3|2017-07-06 12:57:11|       9800|  East Flanders|  BOVBE40_799|           null|             null|\n",
      "|TO-17-015608|TO-17-015608-001|     1|   BO_BAC_MBOVIS_PCR|                   null|            PCR|   null|            1|        BAL|Dairy|      MB|2017-01-20 13:56:04|       3870|  East Flanders| BOVBE70_1206|           null|             null|\n",
      "|TO-17-130740|TO-17-130740-001|     1|   BO_BAC_MBOVIS_PCR|                   null|            PCR|   null|            1|       Swab| Beef|      MB|2017-05-24 11:14:14|       2310|        Limburg|  BOVBE10_204|           null|             null|\n",
      "|TO-17-150691|TO-17-150691-002|     0| AS_BAC_HSO_PCR_POOL|                   null|            PCR|   null|            1|        BAL| Beef|      HS|2017-06-21 09:04:10|       8950|  West Flanders|  BOVBE30_691|           null|             null|\n",
      "|TO-17-165132|TO-17-165132-008|     0| AS_BAC_HSO_PCR_POOL|                   null|            PCR|   null|            1|       Swab| Veal|      HS|2017-07-10 15:21:03|       2460|        Limburg|VCALFBE10_145|           null|             null|\n",
      "|TO-17-125116|TO-17-125116-005|     0| AS_BAC_HSO_PCR_POOL|                   null|            PCR|   null|            1|        BAL| Beef|      HS|2017-05-17 15:36:07|       3870|  East Flanders| BOVBE70_1110|           null|             null|\n",
      "|TO-16-292562|TO-16-292562-001|     0| AS_BAC_MAN_HAEM_PCR|                   null|            PCR|   null|            1|        BAL| Beef|      MH|2016-12-16 14:15:59|       3910|  East Flanders| BOVBE70_1171|           null|             null|\n",
      "|TO-17-004619|TO-17-004619-001|     0| AS_BAC_MAN_HAEM_PCR|                   null|            PCR|   null|            1|        BAL|Mixed|      MH|2017-01-06 11:24:15|       9280|  East Flanders| BOVBE40_1074|           null|             null|\n",
      "|TO-17-089983|TO-17-089983-003|     0| AS_BAC_MAN_HAEM_PCR|                   null|            PCR|   null|            1|    Autopsy|Mixed|      MH|2017-04-06 11:23:12|       1750|Flemish Brabant|  BOVBE20_321|           null|             null|\n",
      "|TO-17-006552|TO-17-006552-001|     0| AS_BAC_MAN_HAEM_PCR|                   null|            PCR|   null|            1|        BAL|Dairy|      MH|2017-01-10 15:15:18|       2400|        Limburg|  BOVBE10_181|           null|             null|\n",
      "+------------+----------------+------+--------------------+-----------------------+---------------+-------+-------------+-----------+-----+--------+-------------------+-----------+---------------+-------------+---------------+-----------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "barometer.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc30a47d",
   "metadata": {},
   "source": [
    "###Step 03: Iterate over the PySpark DataFrame and map to ontology properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eebb05a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o402.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 32.0 failed 1 times, most recent failure: Lost task 0.0 in stage 32.0 (TID 143) (Saba.home executor driver): TaskResultLost (result lost from block manager)\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2238)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2259)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2278)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1021)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1020)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:424)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:348)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:376)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:348)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:3688)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)\r\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3685)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4584\\2492141492.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbarometer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbarometer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"row_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# add a row ID column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbarometer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0msample_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{row['Diagnostic_test']}-{row['Samplenumber']}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0monto\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"sample_{sample_id}\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    815\u001b[0m         \"\"\"\n\u001b[0;32m    816\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m             \u001b[0msock_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCPickleSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\python\\lib\\py4j-0.10.9.5-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\python\\lib\\py4j-0.10.9.5-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o402.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 32.0 failed 1 times, most recent failure: Lost task 0.0 in stage 32.0 (TID 143) (Saba.home executor driver): TaskResultLost (result lost from block manager)\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2238)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2259)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2278)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1021)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1020)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:424)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:348)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:376)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:348)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:3688)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)\r\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3685)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "barometer = barometer.withColumn(\"row_id\", lit(0))  # add a row ID column\n",
    "for row in barometer.collect():\n",
    "    sample_id = f\"{row['Diagnostic_test']}-{row['Samplenumber']}\"\n",
    "    sample = onto[f\"sample_{sample_id}\"]\n",
    "    g.add((sample, RDF.type, onto.Sample))\n",
    "    g.add((sample, onto.has_country, Literal(row['Country'], datatype=XSD.string)))\n",
    "    g.add((sample, onto.has_sample_type, onto[row['Sample_type']]))\n",
    "    g.add((sample, onto.has_breed, onto[row['Breed']]))\n",
    "    g.add((sample, onto.has_parameter_code, onto[row['Parameter_code']]))\n",
    "    g.add((sample, onto.has_result, Literal(row['Result'], datatype=XSD.string)))\n",
    "    g.add((sample, onto.has_pathogen, onto[row['Pathogen']]))\n",
    "    g.add((sample, onto.has_date, Literal(row['Date'], datatype=XSD.dateTime)))\n",
    "    g.add((sample, onto.has_postal_code, Literal(row['Postal_code'], datatype=XSD.string)))\n",
    "    g.add((sample, onto.has_province, onto[row['Province']]))\n",
    "    g.add((sample, onto.has_farm_ID, onto[row['Farm_ID']]))\n",
    "    if row['Pathogen'] == \"PM\":\n",
    "        pathogen_result = onto[f\"pathogen_result_{sample_id}\"]\n",
    "        g.add((pathogen_result, RDF.type, onto.PathogenResult))\n",
    "        g.add((pathogen_result, onto.has_pathogen_identification, onto[row['Pathogen_identification']]))\n",
    "        g.add((pathogen_result, onto.has_pathogen_result, Literal(row['Pathogen_result'], datatype=XSD.string)))\n",
    "        g.add((sample, onto.has_pathogen_result, pathogen_result))\n",
    "    elif row['Pathogen'] == \"Mycoplasma\":\n",
    "        mycoplasma_result = onto[f\"mycoplasma_result_{sample_id}\"]\n",
    "        g.add((mycoplasma_result, RDF.type, onto.MycoplasmaResult))\n",
    "        g.add((mycoplasma_result, onto.has_mycoplasma_result, Literal(row['Mycoplasma_result'], datatype=XSD.string)))\n",
    "        g.add((sample, onto.has_mycoplasma_result, mycoplasma_result))\n",
    "\n",
    "# print RDF graph (for testing)\n",
    "print(g.serialize(format='turtle'))\n",
    "\n",
    "# output RDF graph to file (replace with your desired filename)\n",
    "with open('output/outputTest01.ttl', 'wb') as f:\n",
    "    f.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b0f63c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
